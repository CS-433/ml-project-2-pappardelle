{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9ed1e2",
   "metadata": {},
   "source": [
    "# Training and predicting with 3D U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7d640",
   "metadata": {},
   "source": [
    " ### 3D U-Net model implementtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b932368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Activation, MaxPool2D, Concatenate, LeakyReLU\n",
    "import tensorflow as tf\n",
    "import kera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d7ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "    x = Conv3D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)   #Not in the original network. \n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv3D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)  #Not in the original network\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "#Encoder block: Conv block followed by maxpooling\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPooling3D((2, 2, 2))(x)\n",
    "    return x, p   \n",
    "\n",
    "#Decoder block\n",
    "#skip features gets input from encoder for concatenation\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "#Build Unet using the blocks\n",
    "def build_unet(input_shape, n_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024) #Bridge\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    if n_classes == 1:  #Binary\n",
    "        activation = 'sigmoid'\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "\n",
    "    outputs = Conv3D(n_classes, 1, padding=\"same\", activation=activation)(d4)\n",
    "    print(activation)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ba82b",
   "metadata": {},
   "source": [
    "### Installation of patchify library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c439f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: patchify in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from patchify) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "#Use patchify to break large volumes into smaller for training\n",
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e0a16",
   "metadata": {},
   "source": [
    "### GPU availability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9de5a9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12616\\1449781351.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'/device:GPU:0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU device not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Found GPU at: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "#Make sure the GPU is available. \n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from patchify import patchify, unpatchify\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a729961",
   "metadata": {},
   "source": [
    "### Images and masks loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaaf8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we load 180x1024x1024 pixel volume. We will break it into patches of 15x64x64 for training with steps of 5x64x64. \n",
    "image = []\n",
    "\n",
    "image.append(io.imread('/images/wt_pom1D_01_07_R3D_REF_image.tif'))\n",
    "image.append(io.imread('/images/wt_pom1D_01_15_R3D_REF_image.tif'))\n",
    "image.append(io.imread('/images/wt_pom1D_01_20_R3D_REF_image.tif'))\n",
    "image.append(io.imread('/images/train/wt_pom1D_01_30_R3D_REF_image.tif'))\n",
    "\n",
    "img_patches = []\n",
    "img_patches.append(patchify(image[0], (16, 64, 64), step=(5, 64, 64)))\n",
    "img_patches.append(patchify(image[1], (16, 64, 64), step=(5, 64, 64))) \n",
    "img_patches.append(patchify(image[2], (16, 64, 64), step=(5, 64, 64)))  \n",
    "img_patches.append(patchify(image[3], (16, 64, 64), step=(5, 64, 64)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096603f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = []\n",
    "\n",
    "mask.append(io.imread('/masks/wt_pom1D_01_07_R3D_REF_mask.tif'))\n",
    "mask.append(io.imread('/masks/wt_pom1D_01_15_R3D_REF_mask.tif'))\n",
    "mask.append(io.imread('/masks/wt_pom1D_01_20_R3D_REF_mask.tif'))\n",
    "mask.append(io.imread('/masks/wt_pom1D_01_30_R3D_REF_mask.tif'))\n",
    "\n",
    "mask_patches = []\n",
    "mask_patches.append(patchify(mask[0], (16, 64, 64), step=(5, 64, 64)))\n",
    "mask_patches.append(patchify(mask[1], (16, 64, 64), step=(5, 64, 64)))  \n",
    "mask_patches.append(patchify(mask[2], (16, 64, 64), step=(5, 64, 64)))  \n",
    "mask_patches.append(patchify(mask[3], (16, 64, 64), step=(5, 64, 64)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516fa29",
   "metadata": {},
   "source": [
    "### Reshape the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4720be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.reshape(img_patches[0], (-1, img_patches[0].shape[3], img_patches[0].shape[4], img_patches[0].shape[5]))\n",
    "input_mask = np.reshape(mask_patches[0], (-1, mask_patches[0].shape[3], mask_patches[0].shape[4], mask_patches[0].shape[5]))\n",
    "\n",
    "for i in range(1, 4):\n",
    "    input_img += np.reshape(img_patches[i], (-1, img_patches[i].shape[3], img_patches[i].shape[4], img_patches[i].shape[5]))\n",
    "    input_mask += np.reshape(mask_patches[i], (-1, mask_patches[i].shape[3], mask_patches[i].shape[4], mask_patches[i].shape[5]))\n",
    "\n",
    "input_img = np.array(input_img)\n",
    "input_mask = np.array(input_mask)\n",
    "\n",
    "print(input_img.shape)\n",
    "print(input_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1328c5",
   "metadata": {},
   "source": [
    "### Removing empy patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_img = np.where(input_mask.mean(axis=(1,2,3)) != 0)[0]\n",
    "\n",
    "input_img = input_img[idx_img]\n",
    "input_mask = input_mask[idx_img]\n",
    "\n",
    "print(input_img.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb603a9e",
   "metadata": {},
   "source": [
    "### Standardize the input images and expand the dimension of the arrays by 1 (to match the input of the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc98620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = input_img / input_img.max() \n",
    "train_img = np.expand_dims(train_img, axis=4)\n",
    "train_mask = np.expand_dims(input_mask, axis=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e8f39",
   "metadata": {},
   "source": [
    "### Binarize the masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a56b0a3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1000\\1749930093.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_mask' is not defined"
     ]
    }
   ],
   "source": [
    "train_mask[train_mask>1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b070de90",
   "metadata": {},
   "source": [
    "### One hot encoding of the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bea181",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=2\n",
    "train_mask_cat = to_categorical(train_mask, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0e018",
   "metadata": {},
   "source": [
    "### Split randomly into training and validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da08034",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1000\\3353077275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mask_cat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_img, train_mask_cat, test_size = 0.20, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902bc3f6",
   "metadata": {},
   "source": [
    "### Define the dice coefficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    smoothing_factor = 1\n",
    "    flat_y_true = K.flatten(y_true)\n",
    "    flat_y_pred = K.flatten(y_pred)\n",
    "    return (2. * K.sum(flat_y_true * flat_y_pred) + smoothing_factor) / (K.sum(flat_y_true) + K.sum(flat_y_pred) + smoothing_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed9de7",
   "metadata": {},
   "source": [
    "### Building our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters for our model.\n",
    "\n",
    "patch_size1 = 16\n",
    "patch_size2 = 64\n",
    "patch_size3 = 64\n",
    "channels=1\n",
    "\n",
    "LR = 0.0001\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "\n",
    "model = build_unet((patch_size1,patch_size2,patch_size3,channels), n_classes)\n",
    "\n",
    "model.compile(optimizer = optim, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=dice_coefficient)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.input_shape)\n",
    "print(X_train.shape)\n",
    "print(model.output_shape)\n",
    "print(y_train.shape)\n",
    "print(\"-------------------\")\n",
    "print(X_train.max()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf063e83",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "history=model.fit(X_train, \n",
    "          y_train,\n",
    "          batch_size=8, \n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb5ab72",
   "metadata": {},
   "source": [
    "### Saving the model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcebd161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model for future use\n",
    "model_path = '/saved_models/3dunetmodel_leaky_bs8_16x64x64_100epochs.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6742b06",
   "metadata": {},
   "source": [
    "### Plotting the training and validation IoU and loss at each epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc467fee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1000\\3906662040.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['dice_coefficient']\n",
    "val_acc = history.history['val_dice_coefficient']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training Dice')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Dice')\n",
    "plt.title('Training and validation Dice')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Dice')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f010d148",
   "metadata": {},
   "source": [
    "### Predict the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264182df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d32cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on the test data\n",
    "y_pred_argmax=np.argmax(y_pred, axis=4)\n",
    "y_test_argmax = np.argmax(y_test, axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_argmax.shape)\n",
    "print(y_test_argmax.shape)\n",
    "print(np.unique(y_pred_argmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcb28d",
   "metadata": {},
   "source": [
    "### Mean IoU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec10065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only works on TF > 2.0\n",
    "from keras.metrics import MeanIoU\n",
    "n_classes = 2\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(y_test_argmax, y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e8728",
   "metadata": {},
   "source": [
    "### Testing random images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test_img_number = random.randint(0, len(X_test)-1)\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth=y_test[test_img_number]\n",
    "\n",
    "test_img_input=np.expand_dims(test_img, 0)\n",
    "\n",
    "\n",
    "test_pred = my_model.predict(test_img_input)\n",
    "test_prediction = np.argmax(test_pred, axis=4)[0,:,:,:]\n",
    "\n",
    "ground_truth_argmax = np.argmax(ground_truth, axis=3)\n",
    "print(ground_truth_argmax.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74178bcb",
   "metadata": {},
   "source": [
    "#### Plotting the testing image, ground truth mask and the prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = random.randint(0, ground_truth_argmax.shape[0]-1)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[slice,:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth_argmax[slice,:,:])\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(test_prediction[slice,:,:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
