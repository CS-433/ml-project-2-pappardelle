{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b139baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac1ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"datasets.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f7f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening hdf5 file\n",
    "f = h5py.File(filename, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5349ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializations \n",
    "gt = []\n",
    "img = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba67517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading masks\n",
    "for key in list(f['time_lapse_train']['gt']):\n",
    "    data = data = np.array(f['time_lapse_train']['gt'][key], dtype=np.int16)\n",
    "    image_name = key.split('.')[0] + \"_mask.tif\"\n",
    "    tifffile.imsave(image_name, data)\n",
    "    data = torch.from_numpy(data)\n",
    "    gt.append(data)\n",
    "    \n",
    "#reading images\n",
    "for key in list(f['time_lapse_train']['img']):\n",
    "    data = data = np.array(f['time_lapse_train']['img'][key], dtype=np.int16)\n",
    "    image_name = key.split('.')[0] + \"_image.tif\"\n",
    "    tifffile.imsave(image_name, data)\n",
    "    data = torch.from_numpy(data)\n",
    "    img.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d0573d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_output = torch.empty((1, 9, 1024, 1024), dtype=torch.int16)\n",
    "gt_output = torch.empty((1, 9, 1024, 1024), dtype=torch.int16)\n",
    "\n",
    "\n",
    "for idx in range(0, 171): \n",
    "    start = idx \n",
    "    end = idx+9\n",
    "        \n",
    "    img1 = img[0][start: end]\n",
    "    img1 = img1[None, :]\n",
    "    img_output = torch.cat((img_output, img1))\n",
    "        \n",
    "    gt1 = gt[0][start: end]\n",
    "    gt1 = gt1[None, :]\n",
    "    gt_output = torch.cat((gt_output, gt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f228d356",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2152\\2006037810.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "img1 = img[0][0:9]\n",
    "img2 = img[0][1:10]\n",
    "\n",
    "img1 = img1[None, :]\n",
    "img2 = img2[None, :]\n",
    "\n",
    "#out = torch.stack((img1, img2))\n",
    "\n",
    "#out = torch.cat((img1, img2), axis=1)\n",
    "out = list(zip(img1, img2))\n",
    "\n",
    "u = out[0][1]\n",
    "\n",
    "\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89bca935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[[404, 387, 382,  ..., 356, 338, 345],\n",
      "         [396, 387, 394,  ..., 350, 359, 342],\n",
      "         [389, 373, 373,  ..., 347, 354, 354],\n",
      "         ...,\n",
      "         [356, 371, 355,  ..., 354, 346, 355],\n",
      "         [355, 364, 366,  ..., 332, 343, 367],\n",
      "         [358, 365, 365,  ..., 342, 362, 344]],\n",
      "\n",
      "        [[370, 379, 392,  ..., 354, 344, 349],\n",
      "         [386, 382, 380,  ..., 341, 350, 354],\n",
      "         [382, 377, 385,  ..., 350, 352, 352],\n",
      "         ...,\n",
      "         [371, 365, 362,  ..., 350, 357, 359],\n",
      "         [351, 365, 347,  ..., 347, 355, 349],\n",
      "         [372, 378, 377,  ..., 361, 350, 358]],\n",
      "\n",
      "        [[372, 377, 380,  ..., 362, 356, 351],\n",
      "         [376, 398, 384,  ..., 333, 347, 358],\n",
      "         [384, 389, 401,  ..., 345, 352, 344],\n",
      "         ...,\n",
      "         [371, 365, 376,  ..., 348, 365, 365],\n",
      "         [354, 356, 372,  ..., 350, 349, 345],\n",
      "         [356, 363, 361,  ..., 352, 361, 364]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[384, 374, 382,  ..., 356, 347, 346],\n",
      "         [379, 380, 369,  ..., 357, 355, 361],\n",
      "         [368, 377, 394,  ..., 356, 357, 350],\n",
      "         ...,\n",
      "         [375, 358, 369,  ..., 353, 347, 359],\n",
      "         [357, 366, 353,  ..., 354, 348, 354],\n",
      "         [370, 353, 359,  ..., 345, 358, 347]],\n",
      "\n",
      "        [[367, 375, 406,  ..., 342, 343, 368],\n",
      "         [384, 393, 379,  ..., 367, 341, 355],\n",
      "         [369, 369, 367,  ..., 360, 346, 359],\n",
      "         ...,\n",
      "         [351, 351, 375,  ..., 364, 351, 352],\n",
      "         [356, 358, 379,  ..., 348, 364, 355],\n",
      "         [382, 364, 352,  ..., 363, 336, 362]],\n",
      "\n",
      "        [[398, 375, 400,  ..., 360, 354, 344],\n",
      "         [383, 386, 385,  ..., 353, 353, 348],\n",
      "         [385, 384, 382,  ..., 355, 346, 348],\n",
      "         ...,\n",
      "         [370, 363, 361,  ..., 363, 368, 354],\n",
      "         [364, 378, 362,  ..., 364, 349, 352],\n",
      "         [361, 369, 372,  ..., 347, 352, 361]]], dtype=torch.int16), tensor([[[370, 379, 392,  ..., 354, 344, 349],\n",
      "         [386, 382, 380,  ..., 341, 350, 354],\n",
      "         [382, 377, 385,  ..., 350, 352, 352],\n",
      "         ...,\n",
      "         [371, 365, 362,  ..., 350, 357, 359],\n",
      "         [351, 365, 347,  ..., 347, 355, 349],\n",
      "         [372, 378, 377,  ..., 361, 350, 358]],\n",
      "\n",
      "        [[372, 377, 380,  ..., 362, 356, 351],\n",
      "         [376, 398, 384,  ..., 333, 347, 358],\n",
      "         [384, 389, 401,  ..., 345, 352, 344],\n",
      "         ...,\n",
      "         [371, 365, 376,  ..., 348, 365, 365],\n",
      "         [354, 356, 372,  ..., 350, 349, 345],\n",
      "         [356, 363, 361,  ..., 352, 361, 364]],\n",
      "\n",
      "        [[377, 389, 384,  ..., 343, 359, 350],\n",
      "         [374, 378, 382,  ..., 347, 355, 352],\n",
      "         [381, 378, 378,  ..., 368, 352, 364],\n",
      "         ...,\n",
      "         [360, 369, 361,  ..., 243, 254, 251],\n",
      "         [374, 367, 357,  ..., 256, 254, 254],\n",
      "         [388, 356, 364,  ..., 253, 249, 253]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[367, 375, 406,  ..., 342, 343, 368],\n",
      "         [384, 393, 379,  ..., 367, 341, 355],\n",
      "         [369, 369, 367,  ..., 360, 346, 359],\n",
      "         ...,\n",
      "         [351, 351, 375,  ..., 364, 351, 352],\n",
      "         [356, 358, 379,  ..., 348, 364, 355],\n",
      "         [382, 364, 352,  ..., 363, 336, 362]],\n",
      "\n",
      "        [[398, 375, 400,  ..., 360, 354, 344],\n",
      "         [383, 386, 385,  ..., 353, 353, 348],\n",
      "         [385, 384, 382,  ..., 355, 346, 348],\n",
      "         ...,\n",
      "         [370, 363, 361,  ..., 363, 368, 354],\n",
      "         [364, 378, 362,  ..., 364, 349, 352],\n",
      "         [361, 369, 372,  ..., 347, 352, 361]],\n",
      "\n",
      "        [[373, 392, 371,  ..., 350, 354, 349],\n",
      "         [373, 390, 395,  ..., 358, 335, 349],\n",
      "         [379, 390, 387,  ..., 358, 355, 345],\n",
      "         ...,\n",
      "         [366, 367, 360,  ..., 357, 347, 356],\n",
      "         [361, 363, 358,  ..., 347, 352, 358],\n",
      "         [379, 370, 368,  ..., 347, 358, 359]]], dtype=torch.int16))]\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3bbb77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(img1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba2896f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60965340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([172, 9, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(img_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03560934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([172, 9, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(img_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60f40260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([172, 9, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(gt_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbfcc43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
