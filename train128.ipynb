{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9ed1e2",
   "metadata": {},
   "source": [
    "# 3D U-Net implementation for Binary Segmentation task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7d640",
   "metadata": {},
   "source": [
    " ### Create the four pair of images and masks tif files from the initial h5df file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b932368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "import torch\n",
    "\n",
    "##you need to download the hdf5 data set into the same folder as this Colab Notebook \n",
    "\n",
    "#filename of the data set\n",
    "filename = \"datasets.hdf5\"\n",
    "\n",
    "#opening hdf5 file\n",
    "f = h5py.File(filename, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ddd863",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Colab Notebooks/masks #read masks from folder /masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8519bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading masks\n",
    "for key in list(f['time_lapse_train']['gt']):\n",
    "    data = data = np.array(f['time_lapse_train']['gt'][key], dtype=np.int16)\n",
    "    image_name = key.split('.')[0] + \"_mask.tif\"\n",
    "    tifffile.imsave(image_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece89fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Colab Notebooks/images # Read images from folder /images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ae00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading images\n",
    "for key in list(f['time_lapse_train']['img']):\n",
    "    data = data = np.array(f['time_lapse_train']['img'][key], dtype=np.int16)\n",
    "    image_name = key.split('.')[0] + \"_image.tif\"\n",
    "    tifffile.imsave(image_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dec563",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Colab Notebooks/ # Back to the main folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8f1ee7",
   "metadata": {},
   "source": [
    "## Building the 3D UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d7ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Activation, MaxPool2D, Concatenate, LeakyReLU\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    \"\"\"Convolution block that goes down the U shape of the UNet model.\n",
    "    Args:\n",
    "        input:         array input X_train of 3D dimension (D,H,W), where D is the depth, H the height and W the width\n",
    "        num_filters:   number of filters of the convolution, a scalar\n",
    "    Returns:\n",
    "        x:             convolved output, an array of 3D dimension (D,H,W)\n",
    "    \"\"\"\n",
    "    x = Conv3D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv3D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    \"\"\"Encoder block: convolution block followed by maxpooling.\n",
    "    Args:\n",
    "        input:         array input X_train of 3D dimension (D,H,W), where D is the depth, H the height and W the width\n",
    "        num_filters:   number of filters of the convolution, a scalar\n",
    "    Returns:\n",
    "        x:             convolved input, an array of 3D dimension (D,H,W)\n",
    "        p:             encoded input, an array of 3D dimension (D,H,W)\n",
    "    \"\"\"\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPooling3D((2, 2, 2))(x)\n",
    "    return x, p   \n",
    "\n",
    "#Decoder block\n",
    "#skip features gets input from encoder for concatenation\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    \"\"\"Decoder block: apply transposed convolution and concatenate the input with the skip features.\n",
    "    Args:\n",
    "        input:         array input X_train of 3D dimension (D,H,W), where D is the depth, H the height and W the width\n",
    "        skip_features: array input of 3D dimension (D,H,W), this is the input from the encoder for concatenation\n",
    "        num_filters:   number of filters of the convolution, a scalar\n",
    "    Returns:\n",
    "        x:             decoded input, an array of 3D dimension (D,H,W)\n",
    "    \"\"\"\n",
    "    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "#Build Unet using the blocks\n",
    "def build_unet(input_shape, n_classes):\n",
    "    \"\"\"Building the UNet model using the encoder and decoder blocks. \n",
    "    Args:\n",
    "        input_shape:   shape of the input array, tuple (D,H,W) when D is the depth, H the height and W the width\n",
    "        n_classes:     number of input classes, a scalar\n",
    "    Returns:\n",
    "        model:         3D UNet model \n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024) #Bridge\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    if n_classes == 1:  #Binary\n",
    "        activation = 'sigmoid'\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "\n",
    "    outputs = Conv3D(n_classes, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n",
    "    print(activation)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ba82b",
   "metadata": {},
   "source": [
    "### Installation of patchify library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c439f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: patchify in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from patchify) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "#Use patchify to break large volumes into smaller for training \n",
    "#and also to put patches back together after prediction.\n",
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e0a16",
   "metadata": {},
   "source": [
    "### GPU availability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9de5a9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12616\\1449781351.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'/device:GPU:0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU device not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Found GPU at: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "#Make sure the GPU is available. \n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ac8e59",
   "metadata": {},
   "source": [
    "### Loading the four pairs of images and masks tif files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from patchify import patchify, unpatchify\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaaf8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load input images and masks. \n",
    "#Here we load 180x1024x1024 pixel volume. We will break it into patches of 16x128x128 for training, with a separation step of 5x128x128.\n",
    "#This means that there is an overlap between the first patch and the next one of 5 in the depth dimension. \n",
    "\n",
    "#IMPORTANT: you need to change the file paths in case you do not upload the tif files in the same folder.. \n",
    "image = []\n",
    "\n",
    "image.append(io.imread('/images/wt_pom1D_01_07_R3D_REF_image.tif'))\n",
    "image.append(io.imread('/images/wt_pom1D_01_15_R3D_REF_image.tif'))\n",
    "image.append(io.imread('/images/wt_pom1D_01_20_R3D_REF_image.tif'))\n",
    "image.append(io.imread('/images/train/wt_pom1D_01_30_R3D_REF_image.tif'))\n",
    "\n",
    "img_patches = []\n",
    "img_patches.append(patchify(image[0], (16, 128, 128), step=(5, 128, 128)))\n",
    "img_patches.append(patchify(image[1], (16, 128, 128), step=(5, 128, 128))) \n",
    "img_patches.append(patchify(image[2], (16, 128, 128), step=(5, 128, 128)))  \n",
    "img_patches.append(patchify(image[3], (16, 128, 128), step=(5, 128, 128)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096603f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = []\n",
    "\n",
    "mask.append(io.imread('/masks/wt_pom1D_01_07_R3D_REF_mask.tif'))\n",
    "mask.append(io.imread('/masks/wt_pom1D_01_15_R3D_REF_mask.tif'))\n",
    "mask.append(io.imread('/masks/wt_pom1D_01_20_R3D_REF_mask.tif'))\n",
    "mask.append(io.imread('/masks/wt_pom1D_01_30_R3D_REF_mask.tif'))\n",
    "\n",
    "mask_patches = []\n",
    "mask_patches.append(patchify(mask[0], (16, 128, 128), step=(5, 128, 128)))\n",
    "mask_patches.append(patchify(mask[1], (16, 128, 128), step=(5, 64, 64)))  \n",
    "mask_patches.append(patchify(mask[2], (16, 128, 128), step=(5, 128, 128)))  \n",
    "mask_patches.append(patchify(mask[3], (16, 128, 128), step=(5, 128, 128)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733c18bc",
   "metadata": {},
   "source": [
    "## Data pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516fa29",
   "metadata": {},
   "source": [
    "### Reshape the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4720be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We reshape the patches to get an input image and input mask of shape (N, D, H, W), where N is the total number of patches, \n",
    "# D is the depth size of the patches, H is the height size of the patches, and W is the width size of the patches. \n",
    "input_img = np.reshape(img_patches[0], (-1, img_patches[0].shape[3], img_patches[0].shape[4], img_patches[0].shape[5]))\n",
    "input_mask = np.reshape(mask_patches[0], (-1, mask_patches[0].shape[3], mask_patches[0].shape[4], mask_patches[0].shape[5]))\n",
    "\n",
    "for i in range(1, 4):\n",
    "    input_img += np.reshape(img_patches[i], (-1, img_patches[i].shape[3], img_patches[i].shape[4], img_patches[i].shape[5]))\n",
    "    input_mask += np.reshape(mask_patches[i], (-1, mask_patches[i].shape[3], mask_patches[i].shape[4], mask_patches[i].shape[5]))\n",
    "\n",
    "input_img = np.array(input_img)\n",
    "input_mask = np.array(input_mask)\n",
    "\n",
    "print(input_img.shape)\n",
    "print(input_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1328c5",
   "metadata": {},
   "source": [
    "### Removing empy patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep in a variable all the indices where the patches are empty in the whole sequences \n",
    "idx_img = np.where(input_mask.mean(axis=(1,2,3)) != 0)[0]\n",
    "\n",
    "input_img = input_img[idx_img]\n",
    "input_mask = input_mask[idx_img]\n",
    "\n",
    "#Print the number of patches we have \n",
    "print(input_img.shape[0])\n",
    "print(input_mask.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc98620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the input array of pixels by the maximum value the pixels\n",
    "train_img = input_img / input_img.max() \n",
    "\n",
    "#Expand the dimension of the training sets by 1 to match with the input of the model (i.e. chanel number). \n",
    "train_img = np.expand_dims(train_img, axis=4)\n",
    "train_mask = np.expand_dims(input_mask, axis=4)\n",
    "\n",
    "#Since we are performing a binary segmentation, we need to binarize the masks. \n",
    "train_mask[train_mask>1] = 1\n",
    "\n",
    "#Finally, we perform one hot encoding with the function to_categorical with a chosen number of classes of 2. \n",
    "n_classes=2\n",
    "train_mask_cat = to_categorical(train_mask, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0e018",
   "metadata": {},
   "source": [
    "### Split randomly into training and validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da08034",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1000\\3353077275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mask_cat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_img, train_mask_cat, test_size = 0.20, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902bc3f6",
   "metadata": {},
   "source": [
    "### Define the Dice Coefficient and Dice Coefficient Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#Coefficients that is used during training.\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    \"\"\"Computing the Dice Coefficient.\n",
    "    Args:\n",
    "        y_true:         the ground truth mask of shape (N,D,H,W,C), \n",
    "                        where N is the number of patches, D the depth of patches, H height of patches, \n",
    "                        W width of patches and C the number of channel\n",
    "        y_pred:         the predicted mask by our mode of shape (N,D,H,W,C)\n",
    "    Returns:\n",
    "        dice:           Dice Coefficient computed, a scalar\n",
    "    \"\"\"\n",
    "    smoothing_factor = 1\n",
    "    flat_y_true = K.flatten(y_true)\n",
    "    flat_y_pred = K.flatten(y_pred)\n",
    "    return (2. * K.sum(flat_y_true * flat_y_pred) + smoothing_factor) / (K.sum(flat_y_true) + K.sum(flat_y_pred) + smoothing_factor)\n",
    "\n",
    "#Loss function that might be used during the training.\n",
    "def dice_coefficient_loss(y_true, y_pred):\n",
    "    \"\"\"Computing the Dice Coefficient.\n",
    "      Args:\n",
    "          y_true:         the ground truth mask of shape (N,D,H,W,C), \n",
    "                        where N is the number of patches, D the depth of patches, H height of patches, \n",
    "                        W width of patches and C the number of channel\n",
    "          y_pred:         the predicted mask by our mode of shape (N,D,H,W,C)\n",
    "      Returns:\n",
    "          loss:           Dice Coefficient Loss computed, a scalar\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_pred, tf.float32)\n",
    "    return 1 - dice_coefficient(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed9de7",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters for our model.\n",
    "#Here we use patches of size 16x128x128, so the input shape of our model needs to be the same. \n",
    "patch_size1 = 16\n",
    "patch_size2 = 128\n",
    "patch_size3 = 128\n",
    "channels=1\n",
    "\n",
    "LR = 0.0001\n",
    "optim = keras.optimizers.Adam(LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2176375",
   "metadata": {},
   "source": [
    "#### Train with new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our Model with the input size and number of classes chosen\n",
    "model = build_unet((patch_size1,patch_size2,patch_size3,channels), n_classes)\n",
    "\n",
    "# Compile the model with the optimizer and criterion which is the BCE Loss, as a metric we use the Dice Coefficient \n",
    "model.compile(optimizer = optim, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=dice_coefficient)\n",
    "\n",
    "# Print the summary of our Model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f3689",
   "metadata": {},
   "source": [
    "#### Train a pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# In case you want to train from a pre-trained model, run this cell.\n",
    "\n",
    "# Load the pre-trained model and train from it \n",
    "# You need to specify another path file if the pre-trained model is not in the one one we specified, or simply add it to the /saved_models folder\n",
    "model = load_model('/saved_models/3dunetmodel_leaky_bs4_16x128x128.h5', compile=False)\n",
    "model.compile(optimizer = optim, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=dice_coefficient)\n",
    "\n",
    "# Print the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the model and inputs shape\n",
    "print(model.input_shape)\n",
    "print(X_train.shape)\n",
    "print(model.output_shape)\n",
    "print(y_train.shape)\n",
    "print(\"-------------------\")\n",
    "print(X_train.max())  #Shpuld be 1 after scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d88b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "# You need to specify the batch size and the number of epochs. \n",
    "\n",
    "history=model.fit(X_train, \n",
    "          y_train,\n",
    "          batch_size=4, \n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb5ab72",
   "metadata": {},
   "source": [
    "### Saving the model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcebd161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for future use in the folder /saved_models\n",
    "# In case you want to save it in another folder, you need to specify the file path.\n",
    "model_path = '/saved_models/3dunetmodel_leaky_bs4_16x128x128.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6742b06",
   "metadata": {},
   "source": [
    "### Plotting the training and validation IoU and loss at each epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc467fee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1000\\3906662040.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "##plot the training and validation IoU and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['dice_coefficient']\n",
    "val_acc = history.history['val_dice_coefficient']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training Dice')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Dice')\n",
    "plt.title('Training and validation Dice')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Dice')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f010d148",
   "metadata": {},
   "source": [
    "### Prediction with the model we trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Predict with the model trained\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "#Predict on the test data\n",
    "y_pred_argmax=np.argmax(y_pred, axis=4)\n",
    "y_test_argmax = np.argmax(y_test, axis=4)\n",
    "\n",
    "print(y_pred_argmax.shape)\n",
    "print(y_test_argmax.shape)\n",
    "print(np.unique(y_pred_argmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcb28d",
   "metadata": {},
   "source": [
    "### Mean IoU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec10065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using built in keras function for IoU\n",
    "#Only works on TF > 2.0\n",
    "from keras.metrics import MeanIoU\n",
    "n_classes = 2\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(y_test_argmax, y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e8728",
   "metadata": {},
   "source": [
    "### Testing random images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test some random images\n",
    "import random\n",
    "\n",
    "test_img_number = random.randint(0, len(X_test)-1)\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth=y_test[test_img_number]\n",
    "\n",
    "test_img_input=np.expand_dims(test_img, 0)\n",
    "\n",
    "\n",
    "test_pred = my_model.predict(test_img_input)\n",
    "test_prediction = np.argmax(test_pred, axis=4)[0,:,:,:]\n",
    "\n",
    "ground_truth_argmax = np.argmax(ground_truth, axis=3)\n",
    "print(ground_truth_argmax.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74178bcb",
   "metadata": {},
   "source": [
    "#### Plotting the testing image, ground truth mask and the prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = random.randint(0, ground_truth_argmax.shape[0]-1)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[slice,:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth_argmax[slice,:,:])\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(test_prediction[slice,:,:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
